# Evaluation-of-Language-Models
This study evaluates language models in NLI and bias detection, highlighting the effectiveness of fine-tuning over prompting. RoBERTa excelled in both NLI tasks and hallucination detection, achieving the highest recall and F1 scores. Bias analysis revealed persistent gender stereotypes, with RoBERTa showing reduced bias compared to BERT. These results emphasize the value of fine-tuning for enhancing fairness and reliability in language models.![Uploading image.pngâ€¦]()

